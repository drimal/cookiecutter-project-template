{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4c0e489",
   "metadata": {},
   "source": [
    "# Step 3: Results & Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331f48a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example: Load results or analysis data\n",
    "# df_results = pd.read_csv('../results/tables/{{cookiecutter.project_id}}_results.csv')\n",
    "\n",
    "# Example visualization\n",
    "plt.figure()\n",
    "plt.plot([1, 2, 3], [1, 4, 9])\n",
    "plt.title('Example Plot')\n",
    "plt.savefig('../results/figures/{{cookiecutter.project_id}}_example_plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b093d5e1",
   "metadata": {},
   "source": [
    "## Analysis by Prompt ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91585104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load runs\n",
    "df_runs = pd.read_csv('../results/runs/{{cookiecutter.project_id}}_runs.csv')\n",
    "\n",
    "# If Prompt ID exists, group and compare\n",
    "if 'Prompt ID' in df_runs.columns:\n",
    "    print('Mean metrics by Prompt ID:')\n",
    "    display(df_runs.groupby('Prompt ID')['Metric'].mean())\n",
    "\n",
    "    # Visualization\n",
    "    df_runs.groupby('Prompt ID')['Metric'].mean().plot(kind='bar', title='Average Metric by Prompt')\n",
    "    plt.ylabel('Metric')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No Prompt ID field found in run log.')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
